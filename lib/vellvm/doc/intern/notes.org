This file describe the design choices we are following in the way of handling
the notions of undefined behavior and undefined values (i.e. poison and undef)
that llvm supports.


* Testing Infrastructure

** Feature Support
 - Cstrings
 - Varargs
 - Printf
 - Vector instructions 
 - poision


** Support OAT-style tests
 - use "program" rather than "main"

** Step out of "undef -> 0" refinement model?
 - rather than test with "DValue" executable semantics
 - test at the "UValue" level and use some kind of SMT-backed solver to prove equivalence in the tester?

** Dig into Alive
 - How do they deal with "open" code for external function calls

** QuickChick branch
 - merge LLVM AST pp stuff
 - modernize the QuickChick (it currently isn't done)
 - run clang

** LLVM Testing via CSmith
 - try running with CSmith?

** Expand CI coverage



* Undefined behaviors

** List of cases triggering undefined behavior

*** TODO Division (udiv/sdiv/urem/srem) by zero
    In case of division by vector, raises UB if any element of the vector is zero

*** TODO Division overflow
    Some corner case can cause (signed) division to overflow. For instance:
    sdiv -2147483648 -1
    Such cases are UB.

* Poison

  The first notion of undefined value, _poison_, is treated as a (symbolic) specific dynamic value,
  named _DVALUE_Poison_.
  The central property motivating this choice is that all operations remain _deterministic_ when the
  domain of dynamic values is extended to include poison.

** Semantics and poisoned values

   Depending on the operation performed over a poisoned value, two behaviors can be exhibited:
   - either the operation is deemed to be unsafe to execute over certain dvalues, in which case
   it raises _Undefined Behavior_;
   - or it acts as a taint: the operation is performed, but results in a poisoned value.
   An example of the former is division by a poisoned value.
   An example of the former is addition of a poisoned value to another.

   Operands can be classified into two categories: _safe_ operands are such that
   any dynamic value of the appropriate type in place of this operand leads to a
   safe execution; _unsafe_ operands in contrast are such that there exists a
   dynamic value of the appropriate type such that evaluation would raise UB.
   The general rule is that poisoned values in place of safe operands are tainting,
   while poisoned value in place of unsafe operands raise UB.

   Note that [DVALUE_Poison] is not typed, such as:
   %x = add f32 poison 0
   %y = add i32 %x 0
   will not trigger a dynamic error. It should however be statically ruled out by a type checker.

** List of cases generating poison

*** Prohibited overflow marked by nuw/nsw flags (“No Unsigned Wrap” and “No Signed Wrap”)
    Arithmetic operations (add/sub/mul) can be tagged to forbid wrapping on overflow, resulting in poison instead.
    Bitwise operations (shl) use the same flags such that:
    * nuw prohibits shifting non-zero bits
    * nsw prohibits shifting bits disagreeing with the resultant's sign

*** Prohibited rounding marked by the exact flag
    Divisions over integers (udiv/sdiv) can be tagged to be enforced to have a null remainder
    Bitwise operations (lshr,ashr) use the same flags leading to poison if any shifted out bit is
    non-zero.

*** Shifting by more bits than available
    When shifting (ashr/lshr/shl) op1 by op2, if op2 is equal to or larger than the number of bits of op1,
    the operation results in poison.

*** Wrongly indexed 'extractelement'

*** Wrongly indexed 'insertelement'

*** Prohibited out of bound getelementptr by the inbouds flag

** Select and poison

   If _any_ operand of [select] is poison, the result is poison.

   LangRef: "An instruction that depends on a poison value, produces a poison value itself."

   For an expression such as a select, this dependency is on the set of operands.
   This means in particular that [select true 0 poison] still evaluates to poison.

** Vectors and poison

   Considered pointwise, I think.

** List of cases where poison triggers an undefined behavior

*** Branching on poison is UB
    See [denote_terminator]
    Note: _select_ does NOT raise UB however, see [eval_select_h].

*** Store to a poisoned address is UB
    See [denote_instr]
*** Load from a poisoned address is UB
    See [denote_instr]



* Undef

  Contrary to _poison_, _undef_ is _not_ a dynamic value.
  Its intuitive semantics is to represent the set of dynamic values of the corresponding type.

** Incorrect model 1: immediate non-deterministic branching
   As such, we could simply pick in a non-deterministic fashion a [dvalue] when encountering an
   undef value.
   However, an important property is that several reads to a same _undef_ can lead to different results.
   We hence cannot collapse the non-determinism as soon as it happens.

   LangRef: "This example points out that two ‘undef’ operands are not
   necessarily the same. This can be surprising to people (and also matches C
   semantics) where they assume that “X^X” is always zero, even if X is
   undefined."

** Incorrect model 2: a simple symbolic value for _undef_
   By extending _dvalue_ with an additional symbolic value _undef_, we could delay the non-deterministic
   choice such that a different choice is taken every time.
   However, if it is wrong that:
   %x = undef
   %y = %x + %x
   always leads to an even value in y, it is true with the following example:
   %x = undef
   %y = 2 * %x

** Chosen model: symbolic expressions as values
   We hence want to both delay the non-deterministic choice while having other abstract values than the
   simple "any dvalue of a given type" embodied by _undef_ itself.
   We hence introduce _uvalue_, potentially undefined symbolic values, as a subset of _dvalue_.
   They additionally contain a new _undef_ symbolic value, as well as all arithmetic and comparison operators.
   This way, we can build compound expressions representing arbitrary set of [dvalues] of a given type.

   Note that [dvalue] maintain their property that evaluation over them is deterministic.
   There is a trivial injection from [dvalue] into [uvalue] (see [dvalue_to_uvalue]).
   There is a decidable judgment over [uvalue] to test whether they are images of the previous injection, dubbed "defined".
   There is hence an induced decidable partial injection from [uvalue] into [dvalue] (see [uvalue_to_dvalue]).

** Semantics and [uvalue]

   Recall the distinction between safe and unsafe operands.

*** Over safe operands:

    * If both operands are defined, we perform the computation immediately over the corresponding dvalue and reinject the result.
    * If at least one operand is not defined, we construct the new symbolic [uvalue] as an AST of the expression.

*** Over unsafe operands:

    * If the operand is defined, we perform the computation immediately over the
      corresponding dvalue, operation that may raise UB, the same as it used to.
    * If the unsafe operand is not defined, and contrary to the [poison] case, we
    do not always raise UB: the concretization of the [uvalue] may not contain any
    incriminating [dvalue].

    To decide¹ what to do, we hence collapse there the non-determinism via a new event:
    pick (uv: uvalue) (P: Prop): Pick dvalue.
    Ignoring the proposition for now, it provides the [uvalue] at hand to the environment
    and ask it to return a [dvalue], allowing us to continue the execution.
    However, note that we do not wish to fail dynamically in some execution paths if a UB
    may be raised: we want to abort all executions if one of the paths would raise UB.
    We hence pass to the event a predicate _P_ describing a property to be satisfied for
    the execution to proceed in a non-deterministic, and raise UB otherwise.

    For instance, in the case of the second operand of a division hosting a non concrete
    [uvalue] _uv_, we would raise:
    pick uv (forall dv, concretize uv dv -> dv <> 0)
    Where concretize² is a predicate relating a uvalue to the set of dynamic values it
    represents.

    ¹: Note that in the technical sense of the term, we are performing arithmetic
    over a finite set of values, things are always decidable.
    ²: TODO: reuse as much as possible of the dvalue evaluator.

*** Handling pick

**** The main intended handler goes into the Prop monad and contains two rules:
     * If P is not satisfied, trigger UB
     * If P is satisfied, evaluate to any dvalue related by concretize in a non-deterministic way.

**** For the evaluator, an handler can systematically pick 0
     Remark: this raises a concern.

     In this case, the predicate is ignored. This does not mean that we will
     perform an unsafe operation, since the dynamic evaluation will raise UB if
     0 is a problematic value, but it does mean that we may actually reduce where
     the Prop evaluator would have raised UB. For instance in the following case:
     %x = undef - 1
     %y = 1 / %x
     Is this a sound refinement?

** What is the list of cases where we trigger pick?

   Attempt to pick a value when undef is in a crucial place. Such places are:

   - divisor
   - interaction with memory model
   - calls

* The mysterious /InstSimplify/undef.ll test suite

  (EQ) indicates when the inclusion is actually believed (by YZ at least) to be an equality, (INEQ) otherwise.
  (UB) indicates that the justification for the optimization relies on undefined behaviors being raised in the source.
  (WEIRDISH) indicates that it's not completely clear to me yet how to justify properly the transformation.
  (TODO) indicates that it quite clearly makes sense, but does not match our current development.

** test0: mul                                                            :EQ:
   ret i64 undef
   ⊑
   %r = mul i64 undef, undef
   ret i64 %r

   This clearly makes sense, the set of traces are the same

** test1: mul                                                            :EQ:
   ret i64 undef
   ⊑
   %r = mul i64 3, undef
   ret i64 %r

   Assuming that the returned value is observed (which seems fair), this suggests that
   returning _any_ i64 is a sound refinement to returning three times any i64.

   If refinement is indeed defined as a trace inclusion even when it comes to undef,
   and since no flag is provided to mul, then the only way for this to make sense is if 3*Z_64 ~~ Z_64.
   That would be true if 2^64 and 3 are relatively prime, which is true. So it still makes sense.

   Additionally, this makes sense even with the ~nuw~ and ~nsw~,
   because we can relax ~poison~ to ~undef~.

** test2: mul                                                            :EQ:
   ret i64 undef
   ⊑
   %r = mul i64 undef, 3
   ret i64 %r

   No surprise here, rather reassuring that mul seems to commute.

** test3: mul                                                          :INEQ:
   ret i64 0
   ⊑
   %r = mul i64 undef, 6
   ret i64 %r

   Things get slightly stranger here.
   Returning six times any i64 can be refined into returning always 0.
   This actually makes sense: for one, that's obviously sound with respect
   to the set inclusion interpretation, but also as opposed to 3, 6 is not
   relatively prime to 2^64.
   So if in the previous case the general invariant %r contains undef could be
   easily remembered, here it would require more work. LLVM seems to not want
   to bother, and hence collapse the non-determinism.
   However note that these tests illustrate what the specific implementation of
   the llvm compiler does, but if any logic still applies, refining the previous
   examples by returning 0 would also have been _safe_.

** test4: mul                                                          :INEQ:
   ret i64 0
   ⊑
   %r = mul i64 6, undef
   ret i64 %r

   The symmetric case, no surprise

** test5: and                                                            :EQ:
   ret i64 undef
   ⊑
   and i64 undef, undef
   ret i64 %r

   _and_ is a surjection from i64*i64 into i64, so it makes sense.

** test6: or                                                             :EQ:
   ret i64 undef
   ⊑
   or i64 undef, undef
   ret i64 %r

   Idem for _or_

** test7: udiv                                                           :EQ:
   ret i64 undef
   ⊑
   udiv i64 undef, 1
   ret i64 %r

   Seems about right.

** test8: sdiv                                                           :EQ:
   ret i64 undef
   ⊑
   sdiv i64 undef, 1
   ret i64 %r

   Seems about right.

** test9: urem                                                           :EQ:
   ret i64 0
   ⊑
   urem i64 undef, 1
   ret i64 %r

   Same, remainder by 1 is always 0.

** test10: srem                                                          :EQ:
   ret i64 0
   ⊑
   srem i64 undef, 1
   ret i64 %r

   Same, remainder by 1 is always 0.

** TODO test11: shl                                       :MAYBE_EQ:WEIRDISH:
   ret i64 undef
   ⊑
   shl i64 undef, undef
   ret i64 %r

   This one is slightly puzzling.
   It does seem to make sense to say that shifting any value by any width should be able to
   lead to any value, and hence be refined into undef.
   However, the former can also result in poison, that is not "contained" into undef.
   The set inclusion interpretation hence seems broken here.
   In particular, since LangRef clearly states:
   "Call instructions depend on the ret instructions that dynamically transfer control back to them."
   it should actually matter.

   It might make sense as an overapproximation if we consider that a uvalue that is always defined
   but include poison concretizes into poison, that can be itself refined into undef.

   TODO: more investigation

** test11b: shl                                           :MAYBE_EQ:WEIRDISH:
   ret i64 undef
   ⊑
   shl i64 %a, undef
   ret i64 %r

   %a is an argument to the function
   See test11

** test12: ashr                                           :MAYBE_EQ:WEIRDISH:
   ret i64 undef
   ⊑
   ashr i64 undef, undef
   ret i64 %r

   See test11

** test12b: ashr                                          :MAYBE_EQ:WEIRDISH:
   ret i64 undef
   ⊑
   ashr i64 %a, undef
   ret i64 %r

   %a is an argument to the function
   See test11

** test13: lshr                                           :MAYBE_EQ:WEIRDISH:
   ret i64 undef
   ⊑
   lshr i64 undef, undef
   ret i64 %r

   See test11

** test13b: lshr                                          :MAYBE_EQ:WEIRDISH:
   ret i64 undef ⊑ lshr i64 %a, undef; ret i64 %r

   %a is an argument to the function
   See test11

** test14: slt                                                           :EQ:
   ret i1 undef
   ⊑
   %r = icmp slt i64 undef, undef
   ret i1 %r

   As usual, makes sense quite trivially with respect to the set inclusion, no information is lost.

** test15: ult                                                           :EQ:
   ret i1 undef
   ⊑
   %r = icmp ult i64 undef, undef
   ret i1 %r

   As usual, makes sense quite trivially with respect to the set inclusion, no information is lost.

** test16: select                                                        :EQ:
   ret i64 undef
   ⊑
   %r = select i1 undef, i64 undef, i64 %a
   ret i64 %r

   %a is an argument to the function
   Makes sense: among all inclusions we in
   particular have the selector being true and hence any value in the left
   branch. Since evaluating %a is pure, we cannot have more.

** test17: select                                                        :EQ:
   ret i64 undef
   ⊑
   %r = select i1 undef, i64 %a, i64 undef
   ret i64 %r

   Idem

** TODO test18: call                           :MAYBE_UB:MAYBE_INEQ:WEIRDISH:
   [[R:%.*]] = call i64 undef(i64 %a); ret i64 undef
   ⊑
   %r = call i64 (i64) undef(i64 %a)
   ret i64 %r

   If we call a function at the undef address, and return what it gives us back, we retain the call, but can
   return undef instead.
   This one is a bit more puzzling to justify:
   - either it assumes something along the fact that there is somewhere
     a function returning any value over any argument, hence by set inclusion we are correct;
   - or calling a function at an undef address is Undefined Behavior, hence anything goes from there
   (after the call), and for whatever reason they judged this transformation interesting to perform.
   LangRef has literally nothing to say about this...

   TODO: investigate further

** TODO test19: shl over vectors                                  :EQ:
   ret <4 x i8> undef
   ⊑
   %b = shl <4 x i8> %a, <i8 8, i8 9, i8 undef, i8 -1>
   ret <4 x i8> %b

   This emphasize that operations over vectors do not behave as maps of the semantics over the vector.
   Here a single undef legitimates the whole vector to be refined as undef.

   Wasn't there something with poison bits and vectors with respect to
   the "taming undefined behaviour semantics?" Weird.

   https://lists.llvm.org/pipermail/llvm-dev/2018-March/121940.html

** test20: udiv                                                     :UB:INEQ:

   ret i32 undef
   ⊑
   %b = udiv i32 %a, 0
   ret i32 %b

   Division by 0 raises UB, hence everything goes.

** test20vec: udiv over vectors                                     :UB:INEQ:
   ret <2 x i32> undef
   ⊑
   %b = udiv <2 x i32> %a, zeroinitializer
   ret <2 x i32> %b

   The situation is the same when it happens as part of a vector.

** test21: sdiv                                                     :UB:INEQ:
   ret i32 undef
   ⊑
   %b = sdiv i32 %a, 0
   ret i32 %b

   See test20

** test21vec: sdiv over vectors                                     :UB:INEQ:
   ret <2 x i32> undef
   ⊑
   %b = sdiv <2 x i32> %a, zeroinitializer
   ret <2 x i32> %b

   See test20vec

** test22: ashr exact                                   :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = ashr exact i32 undef, %a
   ret i32 %b

   Similar to test11 and all the other shifts, weird interaction between poison and undef.
   I believe however that the 'exact' key word here is irrelevant since poison is already
   raised when undef gets concretized into a value having less bits that %a.

** test23: lshr exact                                   :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = lshr exact i32 undef, %a
   ret i32 %b

   See test22

** test24: udiv by 0                                                     :UB:
   ret i32 undef
   ⊑
   %b = udiv i32 undef, 0
   ret i32 %b

   Division by zero raises UB, anything goes, in particular they chose to return undef.

** test25: lshr                                         :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = lshr i32 0, undef
   ret i32 %b

   Similar to test11 and all the other shifts.
   All concretizations of undef lead to the shift returning poison. It gets refined into undef.

** test26: ashr                                         :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = ashr i32 0, undef
   ret i32 %b

   See test25

** test28: shl                                          :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = shl i32 0, undef
   ret i32 %b

   See test25

** test28: shl nsw                                      :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = shl nsw i32 undef, %a
   ret i32 %b

   Similar to test25, the nsw flag leading to poison being emitted for some concretizations.

** test29: shl nuw                                      :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = shl nuw i32 undef, %a
   ret i32 %b

   Similar to test28.

** test30: shl nsw nuw                                  :MAYBE_INEQ:WEIRDISH:
   ret i32 undef
   ⊑
   %b = shl nsw nuw i32 undef, %a
   ret i32 %b

   Similar to test28.

** test31: shl                                       :INEQ:SLIGHTLY_WEIRDISH:
   ret i32 0
   ⊑
   %b = shl i32 undef, %a
   ret i32 %b

   This one seems to echo the "if the invariant is any subtler than just undef, drop it" approach:
   after shifting, not all patterns can be stored in b, so we chose to lose information by picking
   the value 0.
   However, there a slight concern: depending %a, there's also values concretizing undef that
   result in poison: is it completely orthogonal? I would guess the reasoning is: if there were
   always concretizations leading to poison, then we would refine by undef, but since it depends
   on the argument, we cannot and give up?

** test32: shl                                                           :EQ:
   ret i32 undef
   ⊑
   %b = shl i32 undef, 0
   ret i32 %b

   This one shl seems fairly innocent.

** test33: ashr                                                          :EQ:
   ret i32 undef
   ⊑
   %b = ashr i32 undef, 0
   ret i32 %b

   See test32

** test34: lshr                                                          :EQ:
   ret i32 undef
   ⊑
   %b = lshr i32 undef, 0
   ret i32 %b

   See test32

** test35: extractelement                        :MAYBE_EQ:SLIGHTLY_WEIRDISH:
   ret i32 undef
   ⊑
   %b = extractelement <4 x i32> %V, i32 4
   ret i32 %b

   By extracting out of bound, we get poison, that we are now used to see refined into undef.

** test36: extractelement                        :MAYBE_EQ:SLIGHTLY_WEIRDISH:
   ret i32 undef
   ⊑
   %b = extractelement <4 x i32> undef, i32 %V
   ret i32 %b

   Undef as the vector argument does not change anything.

** test37: udiv                                                 :MAYBE_EQ:UB:
   ret i32 undef
   ⊑
   %b = udiv i32 undef, undef
   ret i32 %b

   Here the refinement seems fair with little doubt, but it's unclear which justification is paramount.
   Most likely: among all pairs of concretizations, some raise UB, hence the whole operation is UB,
   hence everything goes.

** test38: udiv                                                 :MAYBE_EQ:UB:
   ret i32 undef
   ⊑
   %b = udiv i32 %a, undef
   ret i32 %b

   Idem, there's a UB concretization for any input.

** test39: udiv                                                 :MAYBE_EQ:UB:
   ret i32 undef
   ⊑
   %b = udiv i32 0, undef
   ret i32 %b

   Particular case of test38.


* Refinement relation
  
  These relations should be justified by a refinement on programs,
  defined in terms of some flavor of an observational refinement on
  the denotations of these programs.  We however have a significant
  margin in design space to do so.

** Refinement of uvalues

   We first want to define the refinement [R: uvalue -> uvalue -> Prop] as:
   - undef R poison
   - uv1 R uv2 if concretization(uv1) is included in concretization(uv2)

** A hierarchy of refinements?

   Refinements are mainly relations over itrees. We can however define one such for each interface.

*** The _true_ refinement?
    At its core, the one of interest should be defined over the signature containing only UB, i.e. 
    after running all handlers.
    At this level, the denotation returns a [uvalue] wrapped in a state monad of
    a memory, genv, and stack of local env, as well as the Prop monad.
    We essentially want eutt of the trees, except that UB can be refined by any tree:
    The returned [uvalue] should be related by [R], which we can feed to [eutt].
    We hence would have over trees something like:
    - eutt t1 t2 -> t1 ⊑ t2
    - forall t, t ⊑ raiseUB
    It is however unclear how this bisimulation could work: by defining brutally one such inductive,
    we cannot establish that Vis e (fun dv -> k dv) ⊑ Vis e (fun dv -> raiseUB).
    Do we need to redefine the bisimulation from scratch or can we get away with an extension of eutt?
    
    We do not care about the global and local env.
    However we do care about the memory, we need some kind of bijection.
    Finally, we want implication in the Prop monad.

*** Other refinements?

    This being said, the benefit of the approach is to be able to reason at
    various level of abstraction. In particular, before interpretation of
    [MemoryE], we can enforce that the same memory events are emitted. This
    allows to relate only programs that generate exactly the same memory rather
    than up to bijection, but does not require to reason about the memory.

    The governing soundness guarantee should be that if two programs are
    related before interpretation, then their interpretations are related.

    The case of [pick] is interesting. We may want some or all of the following
    rules before its interpretation:
    - PickRefineU: forall P uv1 uv2, uv1 R uv2 -> trigger (pick P uv1) ⊑ trigger (pick P uv2)
    - PickRefineD: forall P dv uv, dv ∈ concretization(uv) -> k dv ⊑ Vis (pick P uv) k
    - PickFails : forall P uv t, (exists dv, dv ∈ concretization uv /\~ P dv) -> t ⊑ trigger (pick P uv)
      + Should we call this PickUB or something instead? Although, we may not need these. -- CB
   
    However arguably maybe those are semantics reasoning and hence should be
    lemma after interpretation rather than rules before?
    
